{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "According to the definition given on [GeeksforGeeks](https://www.geeksforgeeks.org/decision-tree/):\n",
    "\n",
    "**Decision tree** is the most powerful and popular tool for classification and prediction. A Decision tree is a flowchart like tree structure, where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and each leaf node (terminal node) holds a class label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to choose splits?\n",
    "### Misclassification Loss\n",
    "Define L(R): loss function on R. Given C classes, define p hat to be the proportion of examples in R that are of class c. $$ L (missclass) = I - max p hat $$ \n",
    "#### Issues\n",
    "It turns out that in certain cases where one option would seem better than the other, the missclassification loss turns out to be the same. In order to do this we instead define **cross-entropy** loss. $$ Lcross = summation( p hat log(p hat) ) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "Decision trees are used for classification but we could also modify it and use it for regression. These trees are known as **regression trees**.\n",
    "\n",
    "Regression trees work similar to decision trees, but instead of predicting the majority class you can predict the mean of the values left."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
