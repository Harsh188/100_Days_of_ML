{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and Variance\n",
    "\n",
    "When creating models we run into issues where we accidentally **overfit** the dataset. This just means that our model performs perfectly on the training set but when its introduced to the testing data it is unable to uphold its accuracy.\n",
    "A model can also **underfit** when it does not capture the trends of the dataset properly.\n",
    "\n",
    "In general\n",
    "- Models with high **bias** tend to underfit\n",
    "- Models with high **variance** tend to overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "Regularization is a technique used to solve overfitting. The way it works is that it regularizes or shrinks the coefficient estimates towards zero. This reduces the complexity of the model to make sure that it does not overfit the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Step\n",
    "A general step in pre-processing a large dataset is to normalize it. In order to do this we subtract by the mean and divide it by the standard deviation. This also allows us to have a standard lambda when we use our regularization technique. This also makes gradient decent run a lot faster and efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequentist vs Bayesian\n",
    "![Frequentist vs Bayesian](https://miro.medium.com/max/1868/1*tNTGSCBL2yJt85FVa_oRLQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splits\n",
    "This is a method of splitting the dataset into train, development and test groups. Then we would train the model on the train dataset and get some hypothesis and then measure the error using the development dataset. After doing this we then pick the model with the lowest error on the development set. We do this in order to not over fit our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually the **split** is as follows:\n",
    "- Train - 60%\n",
    "- Development - 20%\n",
    "- Test - 20%\n",
    "\n",
    "Or\n",
    "- Train - 70%\n",
    "- Test - 30%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Simple) Hold-out Cross Validation\n",
    "This is pretty much what we disscussed earlier. The **development set** is also known as the **cross validation set**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-fold cross validation\n",
    "There is a procedure you should use if you have a very small dataset. This is known as **K-Fold Cross-Validation**.\n",
    "The k value indicates the number of groups formed. Then for all the groups we train the model on (k-1) peices and then we test on the remaining peices.\n",
    "So if k was equal to 5 we would train on four groups and then test on the 5th we would loop this 5 times to make sure that the group that is being tested on covers all the 5 possible groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process of validation utilizes more of the data since only 10% of the data is used for the testing phase as compared to the splitting method where 30% would be held out.\n",
    "The disadvantage is that its computationally expensive since we will be fittng each model several times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leave-one-out cross validation\n",
    "This is a more extereme version of leave one out cross validation where we divide the dataset into as many peices as there are elements. Then we remove one element and then train the model on these elements and then test it on the left out element.\n",
    "The disadvantage of this is that we would have to run the model m times which becomes super inefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "In some datasets where there are a lot of features we can reduce them by picking the most important to prevent overfitting. \n",
    "\n",
    "Start with an empty set of features\n",
    "Then try adding features to this set and then see which features most improve the performance. Then add that feature.\n",
    "We would repeat this process for all the features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
